{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given the ACME customer survey data, our goal is to classify if a customer is happy or not based on the given answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from feature_engine.variable_transformers import LogTransformer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  pd.read_csv(\"D:\\Apziva\\\\ACME-HappinessSurvey2020.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y  X1  X2  X3  X4  X5  X6\n",
       "0  0   3   3   3   4   2   4\n",
       "1  0   3   2   3   5   4   3\n",
       "2  1   5   3   3   3   3   5\n",
       "3  0   5   4   3   3   3   5\n",
       "4  0   5   4   3   3   3   5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    69\n",
       "0    57\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The target variable seems to be quite balanced\n",
    "data[\"Y\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y     0\n",
       "X1    0\n",
       "X2    0\n",
       "X3    0\n",
       "X4    0\n",
       "X5    0\n",
       "X6    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking for missing values - We don't seem to have any\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y [0 1]\n",
      "X1 [3 5 4 1]\n",
      "X2 [3 2 4 5 1]\n",
      "X3 [3 2 4 5 1]\n",
      "X4 [4 5 3 2 1]\n",
      "X5 [2 4 3 5 1]\n",
      "X6 [4 3 5 2 1]\n"
     ]
    }
   ],
   "source": [
    "# Inspecting the variable values\n",
    "for var in data.columns:\n",
    "    print(var, data[var].unique()[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 7 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exploring the distribution of the data via histograms\n",
    "fig, axes = plt.subplots(ncols=len(data.columns), figsize=(20,5))\n",
    "for col, ax in zip(data, axes):\n",
    "    data[col].value_counts().sort_index().plot.bar(ax=ax, title=col, color=['red', 'orange'])\n",
    "\n",
    "plt.tight_layout()    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The distributions is not exactly normal so we would like to achieve a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data before training our models\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(data.drop('Y',axis=1), data.Y , test_size=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_pipe = Pipeline([\n",
    "    # Transforming the distribution of the data to look normal\n",
    "    ('lt', LogTransformer()),\n",
    "       \n",
    "    # Scaling the variables although we have 4 variables on the same scale except for one - Scaling via mean normalization\n",
    "    (\"standardscaler\" , StandardScaler(with_mean=True, with_std=False)),\n",
    "    (\"robustscaler\" , RobustScaler(with_centering=False, with_scaling=True, quantile_range=(0, 100))) \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_pipe.fit(X_train, y_train)\n",
    "X_train=prep_pipe.transform(X_train)\n",
    "X_val=prep_pipe.transform(X_val)\n",
    "X_test=prep_pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(fbeta_score, beta=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a scorer for F1 score - The F1 score is a optimal metric choice for this kind of dataset wher\n",
    "# rather then focusing on just happy or unhappy customers F1 score helps determine the trade off between the two\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "f1score = make_scorer(fbeta_score, beta=1)\n",
    "f1score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression - with L2 (Ridge) penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Logistic Regression:  {'C': 0.2, 'dual': True, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear', 'warm_start': True} \n",
      "\n",
      "Best Mean Cross-validation score: 0.7695571095571095 \n",
      "\n",
      "Logistic Test Performance:  0.7027027027027027\n",
      "Logistic Validation Performance:  0.5454545454545454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "logreg_l2 = LogisticRegression(max_iter=10000, random_state=42)\n",
    "\n",
    "logreg_param = {'penalty':['l2'],\n",
    "                'dual':[True],\n",
    "                'C':[0.01, 0.1, 0.2, 0.5], \n",
    "                'fit_intercept':[True,False],\n",
    "                'solver':['liblinear'],\n",
    "                'warm_start':[True,False]}\n",
    "\n",
    "logreg_l2_grid = GridSearchCV(logreg_l2, logreg_param, cv=10, return_train_score=True, scoring= f1score)\n",
    "logreg_l2_grid.fit(X_train,y_train)\n",
    "\n",
    "print('Best Parameters for Logistic Regression: ', logreg_l2_grid.best_params_, '\\n')\n",
    "\n",
    "# Mean Cross validation Score\n",
    "print(\"Best Mean Cross-validation score: {}\".format(logreg_l2_grid.best_score_), '\\n')\n",
    "\n",
    "# Check test data set performance\n",
    "print(\"Logistic Test Performance: \", logreg_l2_grid.score(X_test,y_test))\n",
    "print(\"Logistic Validation Performance: \", logreg_l2_grid.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression - with L1 (Lasso) penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Logistic Regression:  {'C': 0.1, 'dual': False, 'fit_intercept': True, 'penalty': 'l1', 'solver': 'saga', 'warm_start': True} \n",
      "\n",
      "Best Mean Cross-validation score: 0.7588578088578088 \n",
      "\n",
      "Logistic Test Performance:  0.6666666666666666\n",
      "Logistic Validation Performance:  0.5714285714285715\n"
     ]
    }
   ],
   "source": [
    "logreg_l1 = LogisticRegression(max_iter=10000, random_state=42)\n",
    "\n",
    "logreg_param = {'penalty':['l1'],\n",
    "                'dual':[False],\n",
    "                'C':[0.001, 0.01, 0.05, 0.1, 0.2, 0.5, 1], \n",
    "                'fit_intercept':[True,False],\n",
    "                'solver':['saga'],\n",
    "#                 'class_weight':[None,'balanced'],\n",
    "                'warm_start':[True,False]}\n",
    "\n",
    "\n",
    "logreg_l1_grid = GridSearchCV(logreg_l1, logreg_param, cv=10, return_train_score=True, scoring= f1score)\n",
    "logreg_l1_grid.fit(X_train,y_train)\n",
    "\n",
    "print('Best Parameters for Logistic Regression: ', logreg_l1_grid.best_params_, '\\n')\n",
    "\n",
    "# Mean Cross validation Score\n",
    "print(\"Best Mean Cross-validation score: {}\".format(logreg_l1_grid.best_score_), '\\n')\n",
    "\n",
    "# Check test data set performance\n",
    "print(\"Logistic Test Performance: \", logreg_l1_grid.score(X_test,y_test))\n",
    "print(\"Logistic Validation Performance: \", logreg_l1_grid.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression - Elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Logistic Regression:  {'C': 0.001, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'l1_ratio': 0.1, 'penalty': 'elasticnet', 'solver': 'saga', 'warm_start': True} \n",
      "\n",
      "Best Mean Cross-validation score: 0.7588578088578088 \n",
      "\n",
      "Logistic Test Performance:  0.6666666666666666\n",
      "Logistic Validation Performance:  0.5714285714285715\n"
     ]
    }
   ],
   "source": [
    "logreg_l1l2 = LogisticRegression(max_iter=10000, random_state=42)\n",
    "\n",
    "logreg_param = {'penalty':['elasticnet'],\n",
    "                'dual':[False],\n",
    "                'C':[0.001, 0.01, 0.1, 1, 10, 100, 1000], \n",
    "                'fit_intercept':[True,False],\n",
    "                'solver':['saga'],\n",
    "                'class_weight':[None,'balanced'],\n",
    "                'warm_start':[True,False],\n",
    "                'l1_ratio':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]}\n",
    "\n",
    "logreg_l1l2_grid = GridSearchCV(logreg_l1l2, logreg_param, cv=10, return_train_score=True, scoring= f1score)\n",
    "logreg_l1l2_grid.fit(X_train,y_train)\n",
    "\n",
    "print('Best Parameters for Logistic Regression: ', logreg_l1l2_grid.best_params_, '\\n')\n",
    "\n",
    "# Mean Cross validation Score\n",
    "print(\"Best Mean Cross-validation score: {}\".format(logreg_l1l2_grid.best_score_), '\\n')\n",
    "\n",
    "# Check test data set performance\n",
    "print(\"Logistic Test Performance: \", logreg_l1l2_grid.score(X_test,y_test))\n",
    "print(\"Logistic Validation Performance: \", logreg_l1l2_grid.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Classifier (L2 Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'alpha': 5, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'normalize': True, 'solver': 'auto'} \n",
      "\n",
      "Best Mean Cross-validation score: 0.7725407925407927 \n",
      "\n",
      "Test Performance:  0.6842105263157895\n",
      "Validation Performance:  0.5294117647058825\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "ridge_clf = RidgeClassifier(random_state = 42)\n",
    "\n",
    "ridge_param = {'alpha':[1,2,5,10,12,15,20,25],\n",
    "               'fit_intercept':[True,False],\n",
    "               'normalize':[True,False],\n",
    "               'copy_X':[True,False],\n",
    "               'class_weight':[None,'balanced'],\n",
    "               'solver':['auto','svd','cholesky','lsqr','sparse_cg','sag','saga']\n",
    "               \n",
    "}\n",
    "\n",
    "ridge_grid = GridSearchCV(ridge_clf, ridge_param, cv=10 ,return_train_score=True ,scoring=f1score)\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "\n",
    "print('Best Parameters: ', ridge_grid.best_params_, '\\n')\n",
    "\n",
    "print(\"Best Mean Cross-validation score: {}\".format(ridge_grid.best_score_), '\\n')\n",
    "\n",
    "print(\"Test Performance: \", ridge_grid.score(X_test,y_test))\n",
    "print(\"Validation Performance: \", ridge_grid.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'algorithm': 'brute', 'n_neighbors': 6, 'weights': 'uniform'} \n",
      "\n",
      "Best Mean Cross-validation score: 0.7313675213675215 \n",
      "\n",
      "Test Performance:  0.5185185185185186\n",
      "Validation Performance:  0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "param_knn = {'n_neighbors': range(5,25), \n",
    "             'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "            'weights':['uniform','distance']}\n",
    "\n",
    "grid_knn = GridSearchCV(knn, param_knn, cv=10, return_train_score=True, scoring= f1score)\n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "print('Best Parameters: ', grid_knn.best_params_, '\\n')\n",
    "\n",
    "print(\"Best Mean Cross-validation score: {}\".format(grid_knn.best_score_), '\\n')\n",
    "\n",
    "print(\"Test Performance: \", grid_knn.score(X_test,y_test))\n",
    "print(\"Validation Performance: \", grid_knn.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'criterion': 'gini', 'max_depth': 2, 'max_leaf_nodes': 4, 'min_samples_split': 2, 'splitter': 'best'} \n",
      "\n",
      "Best Mean Cross-validation score: 0.7894017094017094 \n",
      "\n",
      "Test Performance:  0.6857142857142856\n",
      "Validation Performance:  0.6060606060606061\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "param_dtree = {\"max_depth\": [1,2,3,4,5],\n",
    "           \"min_samples_split\": [2,3,4],\n",
    "           \"max_leaf_nodes\": [2,3,4,5],\n",
    "           \"criterion\":['gini'],\n",
    "           \"splitter\":['best','random']}\n",
    "\n",
    "grid_dtree = GridSearchCV(dtree, param_dtree, cv=10, return_train_score = True, scoring= f1score)\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "print('Best Parameters: ', grid_dtree.best_params_, '\\n')\n",
    "\n",
    "print(\"Best Mean Cross-validation score: {}\".format(grid_dtree.best_score_), '\\n')\n",
    "\n",
    "print(\"Test Performance: \", grid_dtree.score(X_test,y_test))\n",
    "print(\"Validation Performance: \", grid_dtree.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'C': 0.001, 'loss': 'hinge', 'penalty': 'l2'} \n",
      "\n",
      "Best Mean Cross-validation score: 0.7588578088578088 \n",
      "\n",
      "Test Performance:  0.6666666666666666\n",
      "Validation Performance:  0.5294117647058825\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "lsvc = LinearSVC(random_state=42)\n",
    "\n",
    "param = [{'penalty':['l2'],\n",
    "          'C': [0.001, 0.002, 0.0001, 0.008, 0.01, 0.1], \n",
    "          'loss':['hinge','squared_hinge']}]\n",
    "\n",
    "svc_grid = GridSearchCV(lsvc, param, cv=10 ,return_train_score=True ,scoring=f1score)\n",
    "svc_grid.fit(X_train, y_train)\n",
    "\n",
    "print('Best Parameters: ', svc_grid.best_params_, '\\n')\n",
    "\n",
    "print(\"Best Mean Cross-validation score: {}\".format(svc_grid.best_score_), '\\n')\n",
    "\n",
    "print(\"Test Performance: \", svc_grid.score(X_test,y_test))\n",
    "print(\"Validation Performance: \", svc_grid.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'degree': 3, 'kernel': 'poly'} \n",
      "\n",
      "Best Mean Cross-validation score: 0.7821756021756021 \n",
      "\n",
      "Test Performance:  0.6470588235294118\n",
      "Validation Performance:  0.5294117647058825\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "param_grid = [{'kernel': ['rbf'],\n",
    "               'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "               'gamma': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "              {'kernel': ['linear'],\n",
    "               'C': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "              {'kernel': ['poly'],\n",
    "               'degree': [2, 3, 4, 5, 6]},\n",
    "              {'kernel': ['sigmoid'],\n",
    "               'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "               'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}]\n",
    "\n",
    "svm_grid = GridSearchCV(svc, param_grid, cv=10 ,return_train_score=True ,scoring=f1score)\n",
    "svm_grid.fit(X_train, y_train)\n",
    "\n",
    "print('Best Parameters: ', svm_grid.best_params_, '\\n')\n",
    "\n",
    "print(\"Best Mean Cross-validation score: {}\".format(svm_grid.best_score_), '\\n')\n",
    "\n",
    "print(\"Test Performance: \", svm_grid.score(X_test,y_test))\n",
    "print(\"Validation Performance: \", svm_grid.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Gradient Descent Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'alpha': 0.05, 'eta0': 0.1, 'fit_intercept': True, 'l1_ratio': 0.1, 'learning_rate': 'constant', 'penalty': 'l2'} \n",
      "\n",
      "Best Mean Cross-validation score: 0.7652680652680653 \n",
      "\n",
      "Test Performance:  0.6842105263157895\n",
      "Validation Performance:  0.5294117647058825\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgdc = SGDClassifier(random_state=42)\n",
    "sgdc_param = {'penalty': ['l2', 'l1','elasticnet'],\n",
    "              'l1_ratio': [0.1,0.3,0.5,0.7,0.9],\n",
    "                      'alpha': [0.0001, 0.001, 0.01, 0.02, 0.05, 1, 10],\n",
    "                      'fit_intercept': [True, False],\n",
    "                      'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "                      'eta0': [0.001, 0.01,0.05,0.1,0.2,0.3,0.4,0.5]\n",
    "                     }    \n",
    "\n",
    "sgdc_grid = GridSearchCV(sgdc, sgdc_param, cv=10, return_train_score = True, scoring= f1score)\n",
    "sgdc_grid.fit(X_train, y_train)\n",
    "\n",
    "print('Best Parameters: ', sgdc_grid.best_params_, '\\n')\n",
    "\n",
    "print(\"Best Mean Cross-validation score: {}\".format(sgdc_grid.best_score_), '\\n')\n",
    "\n",
    "print(\"Test Performance: \", sgdc_grid.score(X_test,y_test))\n",
    "print(\"Validation Performance: \", sgdc_grid.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'priors': None, 'reg_param': 0.2, 'tol': 0.0001} \n",
      "\n",
      "Best Mean Cross-validation score: 0.7422843822843823 \n",
      "\n",
      "Test Performance:  0.7222222222222222\n",
      "Validation Performance:  0.5454545454545454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "param_grid = {\n",
    "    'reg_param': [0.001,0.01,0.1,0.3,0.5,0.7],\n",
    "    'priors': [None],\n",
    "    'reg_param': [0,0.2,0.1],\n",
    "    'tol': [0.0001, 0.001]\n",
    "    }    \n",
    "\n",
    "qda_grid = GridSearchCV(QuadraticDiscriminantAnalysis(), param_grid, scoring=f1score, cv=10,  n_jobs=-1)\n",
    "\n",
    "qda_grid.fit(X_train,y_train)\n",
    "\n",
    "print('Best Parameters: ', qda_grid.best_params_, '\\n')\n",
    "\n",
    "print(\"Best Mean Cross-validation score: {}\".format(qda_grid.best_score_), '\\n')\n",
    "\n",
    "print(\"Test Performance: \", qda_grid.score(X_test,y_test))\n",
    "print(\"Validation Performance: \", qda_grid.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'shrinkage': 0.3, 'solver': 'lsqr'} \n",
      "\n",
      "Best Mean Cross-validation score: 0.7237878787878788 \n",
      "\n",
      "Test Performance:  0.7096774193548387\n",
      "Validation Performance:  0.5185185185185185\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "param_grid = {'solver' : ['lsqr', 'eigen'],\n",
    "              'shrinkage': [None, 0.0001, 0.001, 0.01, 0.0005, 0.005, 0.05, 0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]}    \n",
    "\n",
    "lda_grid = GridSearchCV(LinearDiscriminantAnalysis(), param_grid, scoring=f1score, cv=10, n_jobs=-1)\n",
    "\n",
    "lda_grid.fit(X_train,y_train)\n",
    "\n",
    "print('Best Parameters: ', lda_grid.best_params_, '\\n')\n",
    "\n",
    "print(\"Best Mean Cross-validation score: {}\".format(lda_grid.best_score_), '\\n')\n",
    "\n",
    "print(\"Test Performance: \", lda_grid.score(X_test,y_test))\n",
    "print(\"Validation Performance: \", lda_grid.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bootstrap Aggregated Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'base_estimator__max_depth': 1, 'max_samples': 0.8, 'n_estimators': 100} \n",
      "\n",
      "Best Mean Cross-validation score: 0.7745153397327311 \n",
      "\n",
      "Test Performance:  0.6857142857142856\n",
      "Validation Performance:  0.6060606060606061\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag_dtree1 = BaggingClassifier(base_estimator=DecisionTreeClassifier(), bootstrap=True, random_state=0, oob_score=False)\n",
    "\n",
    "bag_dtree1_param = {\n",
    "                 'base_estimator__max_depth': [1,2,3],\n",
    "                 'base_estimator__max_leaf_nodes': [2,3,4,5],\n",
    "                 'base_estimator__min_samples_split':[2,3,4],\n",
    "                 'base_estimator__criterion':['gini','entropy'],\n",
    "                 'max_samples':  [0.8,1],\n",
    "                 'n_estimators': [50,100,200]}\n",
    "\n",
    "bag_dtree1_grid = GridSearchCV(bag_dtree1, bag_dtree1_param,cv=5, return_train_score=True, scoring=f1score)\n",
    "bag_dtree1_grid.fit(X_train,y_train)\n",
    "\n",
    "print('Best Parameters: ', bag_dtree1_grid.best_params_, '\\n')\n",
    "\n",
    "print(\"Best Mean Cross-validation score: {}\".format(bag_dtree1_grid.best_score_), '\\n')\n",
    "\n",
    "print(\"Test Performance: \", bag_dtree1_grid.score(X_test,y_test))\n",
    "print(\"Validation Performance: \", bag_dtree1_grid.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 100} \n",
      "\n",
      "Best Mean Cross-validation score: 0.7725252525252525 \n",
      "\n",
      "Test Performance:  0.6470588235294118\n",
      "Validation Performance:  0.6451612903225806\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc =RandomForestClassifier(random_state=42, oob_score=False)\n",
    "rfc_param = { \n",
    "    'n_estimators': [20,50,100],\n",
    "    'max_features': ['auto'],\n",
    "    'max_depth' : [2,3,4],\n",
    "    'criterion' :['gini', 'entropy'],\n",
    "    'min_samples_split':[2,3,4,5],\n",
    "    'min_samples_leaf':[1,2,3]\n",
    "}\n",
    "\n",
    "rfc_grid = GridSearchCV(rfc, rfc_param,cv=10, return_train_score=True, scoring=f1score)\n",
    "rfc_grid.fit(X_train,y_train)\n",
    "\n",
    "print('Best Parameters: ', rfc_grid.best_params_, '\\n')\n",
    "\n",
    "print(\"Best Mean Cross-validation score: {}\".format(rfc_grid.best_score_), '\\n')\n",
    "\n",
    "print(\"Test Performance: \", rfc_grid.score(X_test,y_test))\n",
    "print(\"Validation Performance: \", rfc_grid.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 200} \n",
      "\n",
      "Best Mean Cross-validation score: 0.7821756021756021 \n",
      "\n",
      "Test Performance:  0.6857142857142856\n",
      "Validation Performance:  0.6060606060606061\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc =RandomForestClassifier(random_state=42, oob_score=False)\n",
    "rfc_param = { \n",
    "    'n_estimators': [100,200,250,300,350,500],\n",
    "    'max_features': ['auto'],\n",
    "    'max_depth' : [2,3,4],\n",
    "    'criterion' :['gini'],\n",
    "    'min_samples_split':[2,3],\n",
    "    'min_samples_leaf':[1,2,3]\n",
    "}\n",
    "\n",
    "rfc_grid = GridSearchCV(rfc, rfc_param,cv=10, return_train_score=True, scoring=f1score)\n",
    "rfc_grid.fit(X_train,y_train)\n",
    "\n",
    "print('Best Parameters: ', rfc_grid.best_params_, '\\n')\n",
    "\n",
    "print(\"Best Mean Cross-validation score: {}\".format(rfc_grid.best_score_), '\\n')\n",
    "\n",
    "print(\"Test Performance: \", rfc_grid.score(X_test,y_test))\n",
    "print(\"Validation Performance: \", rfc_grid.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Trees Classfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 50} \n",
      "\n",
      "Best Mean Cross-validation score: 0.7915695415695416 \n",
      "\n",
      "Test Performance:  0.6857142857142856\n",
      "Validation Performance:  0.6060606060606061\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.ensemble import ExtraTreesClassifier\n",
    "etc= ExtraTreesClassifier(random_state=42)\n",
    "etc_param = { \n",
    "    'n_estimators': [20, 50, 150, 500],\n",
    "    'max_features': ['auto'],\n",
    "    'max_depth' : [2,3,4,10,12],\n",
    "    'criterion' :['gini','entropy'],\n",
    "    'min_samples_split':[2,3,5,7,9],\n",
    "    'min_samples_leaf':[1,2,3]\n",
    "}\n",
    "etc_grid = GridSearchCV(etc, etc_param, cv=10, return_train_score=True, scoring=f1score)\n",
    "etc_grid.fit(X_train,y_train)\n",
    "\n",
    "print('Best Parameters: ', etc_grid.best_params_, '\\n')\n",
    "\n",
    "print(\"Best Mean Cross-validation score: {}\".format(etc_grid.best_score_), '\\n')\n",
    "\n",
    "print(\"Test Performance: \", etc_grid.score(X_test,y_test))\n",
    "print(\"Validation Performance: \", etc_grid.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'n_estimators': 20, 'learning_rate': 1, 'base_estimator__splitter': 'best', 'base_estimator__min_samples_split': 3, 'base_estimator__min_samples_leaf': 2, 'base_estimator__max_depth': 1, 'algorithm': 'SAMME'} \n",
      "\n",
      "Best Mean Cross-validation score: 0.6787878787878787 \n",
      "\n",
      "Test Performance:  0.6857142857142856\n",
      "Validation Performance:  0.625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adc_dtree =AdaBoostClassifier(base_estimator=DecisionTreeClassifier(),random_state=42)\n",
    "adc_dtree_param = {\n",
    "              'base_estimator__splitter' :   ['best','random'],\n",
    "              'base_estimator__max_depth' : [1,2,3],\n",
    "              'base_estimator__min_samples_split':[2,3,4],\n",
    "              'base_estimator__min_samples_leaf':[1,2,3],\n",
    "              'algorithm' : ['SAMME', 'SAMME.R'],\n",
    "              'n_estimators' : [20,50,100,150,300],\n",
    "              'learning_rate' : [0.6, 0.7, 0.8,1],\n",
    "             }\n",
    "\n",
    "adc_dtree_grid = RandomizedSearchCV(adc_dtree, adc_dtree_param, cv=10, return_train_score=True, scoring=f1score)\n",
    "adc_dtree_grid.fit(X_train,y_train)\n",
    "\n",
    "print('Best Parameters: ', adc_dtree_grid.best_params_, '\\n')\n",
    "\n",
    "print(\"Best Mean Cross-validation score: {}\".format(adc_dtree_grid.best_score_), '\\n')\n",
    "\n",
    "print(\"Test Performance: \", adc_dtree_grid.score(X_test,y_test))\n",
    "print(\"Validation Performance: \", adc_dtree_grid.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'learning_rate': 0.2, 'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 20, 'subsample': 1, 'warm_start': True} \n",
      "\n",
      "Best Mean Cross-validation score: 0.7731351981351979 \n",
      "\n",
      "Test Performance:  0.6666666666666667\n",
      "Validation Performance:  0.6206896551724138\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc= GradientBoostingClassifier(random_state=42)\n",
    "gbc_param = {\n",
    "              'min_samples_split':[2,3,4,5,6],\n",
    "              'subsample':[0.8,1],\n",
    "              'min_samples_leaf':[1,2,3],\n",
    "              'max_depth' : [1,2,3,4],\n",
    "#               'max_features':['auto'],\n",
    "              'n_estimators' : [20,50,100,150],\n",
    "              'learning_rate' : [0.2,0.3,0.7,0.5,0.9],\n",
    "              'warm_start' : [True, False]\n",
    "             }\n",
    "\n",
    "gbc_grid = GridSearchCV(gbc, gbc_param,cv=10, return_train_score=True, scoring=f1score)\n",
    "gbc_grid.fit(X_train,y_train)\n",
    "\n",
    "print('Best Parameters: ', gbc_grid.best_params_, '\\n')\n",
    "\n",
    "print(\"Best Mean Cross-validation score: {}\".format(gbc_grid.best_score_), '\\n')\n",
    "\n",
    "print(\"Test Performance: \", gbc_grid.score(X_test,y_test))\n",
    "print(\"Validation Performance: \", gbc_grid.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'colsample_bytree': 0.7, 'early_stopping_rounds': 10, 'eta': 0.01, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1} \n",
      "\n",
      "Best Mean Cross-validation score: 0.7957109557109556 \n",
      "\n",
      "Test Performance:  0.6470588235294118\n",
      "Validation Performance:  0.6451612903225806\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgbc= XGBClassifier(random_state=42, n_jobs=-1, objective = 'binary:logistic')\n",
    "xgbc_param = {\n",
    "              'max_depth' : [2,3,4],\n",
    "              'learning_rate':[0.001, 0.01, 0.1],\n",
    "              'early_stopping_rounds':[10,15],\n",
    "              'n_estimators' : [20,50,100,500],\n",
    "              'eta':[0.01,0.025,0.05,0.1],\n",
    "              'gamma' : [0.6,0.8,1],\n",
    "              'min_child_weight' : [1,2,3],\n",
    "              'subsample': [0.8, 1],\n",
    "              'colsample_bytree': [0.7, 0.9, 1]\n",
    "             }\n",
    "\n",
    "\n",
    "xgbc_grid = GridSearchCV(xgbc, xgbc_param, cv=10, return_train_score=True, scoring = f1score)\n",
    "xgbc_grid.fit(X_train,y_train)\n",
    "\n",
    "print('Best Parameters: ', xgbc_grid.best_params_, '\\n')\n",
    "\n",
    "print(\"Best Mean Cross-validation score: {}\".format(xgbc_grid.best_score_), '\\n')\n",
    "\n",
    "print(\"Test Performance: \", xgbc_grid.score(X_test,y_test))\n",
    "print(\"Validation Performance: \", xgbc_grid.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "cat = CatBoostClassifier()\n",
    "\n",
    "param_grid = {\n",
    "            'depth':[1,2,3,4,7],\n",
    "            'iterations':[250,100,500,1000], \n",
    "            'learning_rate':[0.03,0.001,0.01,0.1,0.2,0.3], \n",
    "            'l2_leaf_reg':[3,1,5,10,100], \n",
    "            'border_count':[32,5,10,20,50,100,200]\n",
    "                      }\n",
    "\n",
    "cat_grid = RandomizedSearchCV(cat, param_grid, cv=10, return_train_score=True, scoring = f1score)\n",
    "cat_grid.fit(X_train,y_train)\n",
    "\n",
    "print('Best Parameters: ', cat_grid.best_params_, '\\n')\n",
    "\n",
    "print(\"Best Mean Cross-validation score: {}\".format(cat_grid.best_score_), '\\n')\n",
    "\n",
    "print(\"Test Performance: \", cat_grid.score(X_test,y_test))\n",
    "print(\"Validation Performance: \", cat_grid.score(X_val,y_val)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameters:  {'learning_rate': 0.001, 'l2_leaf_reg': 10, 'iterations': 500, 'depth': 1, 'border_count': 100} \n",
    "\n",
    "Best Mean Cross-validation score: 0.778951048951049 \n",
    "\n",
    "Test Performance:  0.6666666666666667\n",
    "Validation Performance:  0.6060606060606061"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'reg_lambda': 0.4, 'reg_alpha': 0.7, 'num_leaves': 200, 'n_estimators': 30, 'min_split_gain': 0.9, 'max_depth': 3, 'learning_rate': 0.1} \n",
      "\n",
      "Best Mean Cross-validation score: 0.7361305361305363 \n",
      "\n",
      "Test Performance:  0.6666666666666666\n",
      "Validation Performance:  0.5714285714285715\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "param_grid = {'num_leaves': [10,20,30,40,50,60,70,80,90,100,150,200],\n",
    "              'max_depth': [1,2,3,4],\n",
    "              'learning_rate': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "              'n_estimators': [10, 30, 50, 70, 90, 100, 120, 150, 170, 200], \n",
    "              'min_split_gain' : [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "              'reg_alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "              'reg_lambda': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
    "\n",
    "mdl = lgb.LGBMClassifier(random_state=42,\n",
    "                         objective = 'binary')\n",
    "\n",
    "lgbm_grid = RandomizedSearchCV(mdl, param_grid, cv=10, return_train_score=True, scoring = f1score)\n",
    "lgbm_grid.fit(X_train,y_train)\n",
    "\n",
    "print('Best Parameters: ', lgbm_grid.best_params_, '\\n')\n",
    "\n",
    "print(\"Best Mean Cross-validation score: {}\".format(lgbm_grid.best_score_), '\\n')\n",
    "\n",
    "print(\"Test Performance: \", lgbm_grid.score(X_test,y_test))\n",
    "print(\"Validation Performance: \", lgbm_grid.score(X_val,y_val)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross-validation score: 0.7783372183372184 \n",
      "\n",
      "Test Performance:  0.6857142857142856\n",
      "Validation Performance:  0.5161290322580645\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlpc = MLPClassifier(hidden_layer_sizes=(5,5,5), max_iter = 500, random_state = 42)\n",
    "param = {}\n",
    "\n",
    "mlp_grid= GridSearchCV(mlpc, param, cv=10, return_train_score=True, scoring = f1score)\n",
    "mlp_clf = mlp_grid.fit(X_train,y_train)\n",
    "\n",
    "print(\"Best Mean Cross-validation score: {}\".format(mlp_clf.best_score_), '\\n')\n",
    "\n",
    "print(\"Test Performance: \", mlp_clf.score(X_test,y_test))\n",
    "print(\"Validation Performance: \", mlp_clf.score(X_val,y_val)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross-validation score: 0.6977855477855477 \n",
      "\n",
      "Test Performance:  0.7647058823529412\n",
      "Validation Performance:  0.5517241379310345\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlpc = MLPClassifier(hidden_layer_sizes=(6,3), max_iter = 10000, random_state = 42)\n",
    "param = {}\n",
    "\n",
    "mlp_grid= GridSearchCV(mlpc, param, cv=10, return_train_score=True, scoring = f1score)\n",
    "mlp_clf = mlp_grid.fit(X_train,y_train)\n",
    "\n",
    "print(\"Best Mean Cross-validation score: {}\".format(mlp_clf.best_score_), '\\n')\n",
    "\n",
    "print(\"Test Performance: \", mlp_clf.score(X_test,y_test))\n",
    "print(\"Validation Performance: \", mlp_clf.score(X_val,y_val)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding what data the results are validated on:\n",
    "\n",
    "The Mean Cross Validation Score tells us how well a model has performed with the traning data cross validated with 10 folds - Our training data consists of 77/127 observations.\n",
    "\n",
    "Testing and Validation Set have 25/127 observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Based on a model that would perform better on newer data the best model in my opnon would be the XGBoost Classifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Best Parameters for the XGB Classifier:  {'colsample_bytree': 0.7, 'early_stopping_rounds': 10, 'eta': 0.01, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Best Mean Cross-validation score: 0.7957109557109556 \n",
    "\n",
    "- Test Performance:  0.6470588235294118\n",
    "- Validation Performance:  0.6451612903225806"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Many other models such as the MLP Classifier, QDA, Ridge Classifier, Logistic Regression, AdaBoost gave us really good results on just these particular test and validation sets but may not generalise well on future data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Having access to more data would severely improve performance of many models and be in a position to make better predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importance of Survey Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ridge or L2 regularised model is often considered to be a good feature selector especially in high dimensional datasets (in contrary to our case) due to its ability to penalise attributes that may not be of much value to the model's prediction.\n",
    "\n",
    "- The ridge classifier has performed moderately well as comapred to most other models and observing it's coefficient values will give us a good idea of what features are relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of each feature: [[0.10325073 0.01079386 0.15283796 0.01372126 0.14921793 0.22424348]]\n"
     ]
    }
   ],
   "source": [
    "# Using Logistic regression with l2 - ridge penalty\n",
    "logreg_l2 = LogisticRegression(C = 0.1, dual = True, fit_intercept = True, penalty = 'l2', solver = 'liblinear', \n",
    "                               max_iter=10000, random_state=42)\n",
    "logreg_l2.fit(X_train,y_train)\n",
    "\n",
    "# Identifying which columns have been given preference while making the predictions by checking coefficient values\n",
    "print('Coefficient of each feature:', logreg_l2.coef_)\n",
    "\n",
    "# As we can see from the coefficient values below the order of preference given to the variables in the prediction are:\n",
    "# X6 > X3 > X5 > X1 > X4 > X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of each feature: [[0.20329293 0.0018647  0.1484375  0.01666328 0.10015983 0.0848951 ]]\n"
     ]
    }
   ],
   "source": [
    "ridge_clf = RidgeClassifier(alpha = 5, copy_X = True, fit_intercept = True, solver = 'auto', \n",
    "                               normalize = True, class_weight = None, random_state=42)\n",
    "ridge_clf.fit(X_train,y_train)\n",
    "\n",
    "# Identifying which columns have been given preference while making the predictions by checking coefficient values\n",
    "print('Coefficient of each feature:', ridge_clf.coef_)\n",
    "\n",
    "# As we can see from the coefficient values below the order of preference given to the variables in the prediction are:\n",
    "# X1 > X3 > X5 > X6 > X4 > X2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Based on the coefficient values of the above models it is evident that X2 (contents of my order was as I expected) and X4 (I paid a good price for my order) are both questions that added little to no value in predicting if a customer was happy and are potentially a good choice for questions that could be removed in following surveys. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.319px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
